{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy statsmodels matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargando dataset y uniendo columnas 'Dia', 'Mes', 'Año' en Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap = pd.read_csv('data/ML_data_csv/anexo_circular_7_atencion_primaria.csv')\n",
    "print(df_ap.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_mapping = { 'Enero': 1, 'Febrero': 2, 'Marzo': 3, 'Abril': 4, 'Mayo': 5, 'Junio': 6, 'Julio': 7, 'Agosto': 8, 'Septiembre': 9, 'Octubre': 10, 'Noviembre': 11, 'Diciembre': 12 } \n",
    "# Replace month names with numbers \n",
    "df_ap['Mes'] = df_ap['Mes'].map(month_mapping)\n",
    "# Ensure Dia, Mes, Año columns are of integer type \n",
    "df_ap['Dia'] = df_ap['Dia'].astype(int) \n",
    "df_ap['Mes'] = df_ap['Mes'].astype(int) \n",
    "df_ap['Año'] = df_ap['Año'].astype(int)\n",
    "print(df_ap[['Dia', 'Mes', 'Año']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine Dia, Mes, Año into a single datetime column \n",
    "df_ap['Date'] = pd.to_datetime(df_ap[['Dia', 'Mes', 'Año']].astype(str).agg('-'.join, axis=1), format='%d-%m-%Y')\n",
    "\n",
    "df_ap.set_index('Date', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap.drop(columns=['Dia', 'Mes', 'Año'], inplace=True) \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando nombres de las provincias que aparecen en el dataset para que cada provincia sea una llave en el diccionario province_data_dict y su valor sean los datos correspondientes a esa provincia. Luego se organizan por fecha los datos de cada provincia y se revisa si hay duplicados o valores NAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each province \n",
    "provinces = df_ap['Provincias'].unique()\n",
    "print(provinces)\n",
    "provinces = provinces[:-1] # to delete Total\n",
    "print(provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_data_dict = {}\n",
    "\n",
    "# Iterate over each province and store the data in the dictionary\n",
    "for province in provinces:\n",
    "    province_data = df_ap[df_ap['Provincias'] == province]\n",
    "    province_data.drop(columns=['Provincias'], inplace=True) \n",
    "    province_data_dict[province] = province_data\n",
    "    province_data_dict[province] = province_data_dict[province].sort_index()\n",
    "    # Check for duplicate dates \n",
    "    duplicate_dates = province_data_dict[province].index.duplicated(keep=False) \n",
    "    if duplicate_dates.any(): \n",
    "        print(f\"Duplicate dates found for {province}:\") \n",
    "        print(province_data_dict[province][duplicate_dates])      \n",
    "    \n",
    "    # Check for NaN values\n",
    "    nan_values = province_data.isna().sum()\n",
    "    if nan_values.any():\n",
    "        print(f\"NaN values for {province}:\")\n",
    "        print(nan_values)\n",
    "    # Check for string data types \n",
    "    for column in province_data.columns: \n",
    "        if province_data[column].dtype == 'object': \n",
    "            print(f\"Column '{column}' in province '{province}' contains string data.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Guantánamo hay un valor Nan value en Hogar_A_Fallecidos. Por ahora se va a ignorar esta columna para las predicciones de esta provincia. También se aprecia que la fecha 2023-09-03 (3 de sept del 2023) aparece repetida(con dos filas) en cada provincia. Al revisar el dataset se comprobó que en la entrada correspondiente al 4 de septiembre escribieron 3 de septiembre por error; por tanto se eliminará la repetición de esta cambiándola por 4 de septiembre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_data_dict['Guantánamo'].drop(columns=['Hogar_A_Fallecidos'], inplace=True) \n",
    "nan_values = province_data_dict['Guantánamo'].isna().sum()\n",
    "#Checking for any remaining nan values\n",
    "if nan_values.any():\n",
    "    print(f\"NaN values for 'Guantánamo':\")\n",
    "    print(nan_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for province in provinces:\n",
    "    # Check for duplicate dates \n",
    "    duplicates = province_data_dict[province].index.duplicated(keep='first') \n",
    "    print(province)\n",
    "    print()\n",
    "    print(f'{province_data_dict[province][duplicates]} in {province}')\n",
    "    duplicate_dates = province_data_dict[province][duplicates].index \n",
    "    # Modify the second instance of each duplicate date \n",
    "    for date in duplicate_dates: \n",
    "        # Find all instances of the duplicate date\n",
    "        all_instances_idx = province_data_dict[province].index.get_loc(date)\n",
    "        # Ensure all_instances_idx is a list\n",
    "        if isinstance(all_instances_idx, slice):\n",
    "            all_instances_idx = list(range(all_instances_idx.start, all_instances_idx.stop))\n",
    "        elif isinstance(all_instances_idx, int):\n",
    "            all_instances_idx = [all_instances_idx]\n",
    "        # Modify the date of the second instance\n",
    "        if len(all_instances_idx) > 1:\n",
    "            second_instance_idx = all_instances_idx[1]\n",
    "            province_data_dict[province].index.values[second_instance_idx] = province_data_dict[province].index[second_instance_idx] + pd.Timedelta(days=1)\n",
    "    duplicates = province_data_dict[province].index.duplicated(keep='first') \n",
    "    if duplicates.any():\n",
    "        print()\n",
    "        print(\"After dealing with duplicates\")\n",
    "        print(f'{province_data_dict[province][duplicates]} still in {province}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(province_data_dict['Pinar del Rio'].loc['2023-09-03':'2023-09-04'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empezando a predecir usando ARIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por cada provincia se estimarán los parámetros p y q con ACF y PACF y revisaremos si coincide con los que da autoArima. También comprobaremos si los datos son estacionarios, lo cual es un requerimiento para ARIMA.\n",
    "Columnas a predecir:\n",
    "Hogar_I_Total\tHogar_I_<19aÃ±os\tHogar_A_Recuperados\tHogar_A_Remitidos_ingreso_institucional\tHogar_A_Fallecidos\tHogar_A_Total\tHogar_PI_Total\tHogar_PI_<19aÃ±os\tPoliclinico_I_Total\tPoliclinico_I_<19aÃ±os\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19aÃ±os\tTotalAPS_I_Total\tTotalAPS_I_<19aÃ±os\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19aÃ±os\tPIDA_hogar\tPIDA_hogar_<19aÃ±os\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19aÃ±os\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar_I_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ## Hogar_I_<19años\tHogar_A_Recuperados\tHogar_A_Remitidos_ingreso_institucional\tHogar_A_Fallecidos\tHogar_A_Total\tHogar_PI_Total\tHogar_PI_<19años\tPoliclinico_I_Total\tPoliclinico_I_<19años\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Hogar_I_Total']\n",
    "    print(\"Hogar_I_Total\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#     # Fit ARIMA model (example with p=1, d=1, q=1)\n",
    "#     model = ARIMA(series, order=(1, 1, 1))\n",
    "#     model_fit = model.fit()\n",
    "#     print(model_fit.summary())\n",
    "    \n",
    "#     # Forecast\n",
    "#     forecast = model_fit.forecast(steps=10)\n",
    "#     predictions[province] = forecast\n",
    "\n",
    "# # Print predictions\n",
    "# for province, forecast in predictions.items():\n",
    "#     print(f'Predictions for {province}:')\n",
    "#     print(forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be used to determine the parameters for ARIMA. \n",
    "ACF Plot\n",
    "The ACF plot shows the correlation between the time series and its lagged values. It helps identify the Moving Average (MA) component of the ARIMA model.\n",
    "\n",
    "MA(q) Component: Look for the lag where the ACF plot cuts off (i.e., drops to zero or near zero). The lag at which this happens indicates the order of the MA component (q).\n",
    "\n",
    "PACF Plot\n",
    "The PACF plot shows the correlation between the time series and its lagged values, after removing the effects of intermediate lags. It helps identify the AutoRegressive (AR) component of the ARIMA model.\n",
    "\n",
    "AR(p) Component: Look for the lag where the PACF plot cuts off. The lag at which this happens indicates the order of the AR component (p).\n",
    "\n",
    "Steps to Determine ARIMA Parameters\n",
    "Plot ACF and PACF: Generate the ACF and PACF plots for your time series data.\n",
    "\n",
    "Identify AR(p) and MA(q): Use the ACF and PACF plots to determine the orders of the AR and MA components.\n",
    "\n",
    "Determine Differencing (d): Use the Augmented Dickey-Fuller (ADF) test to check for stationarity. If the series is not stationary, apply differencing until it becomes stationary. The number of times you difference the series is the order of differencing (d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Hogar_I_Total. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Hogar_I_Total. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(test, predictions)\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "nmse = mse / np.var(test)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAPE: {mape}%')\n",
    "print(f'NMSE: {nmse}')\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "plt.plot(test.index, predictions, 'x', label='Predicted', color='red') # Use 'x' for markers \n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(model_fit.summary()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar_I_<19años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_data_dict[\"Artemisa\"].head()\n",
    "province_data_dict[\"Artemisa\"][\"Hogar_I_<19años\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arima_utils import auto_arima_train\n",
    "\n",
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"Hogar_I_<19años\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Hogar_I_<19años. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Hogar_I_<19años. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar_A_Recuperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\tHogar_A_Remitidos_ingreso_institucional\tHogar_A_Fallecidos\tHogar_A_Total\tHogar_PI_Total\tHogar_PI_<19años\tPoliclinico_I_Total\tPoliclinico_I_<19años\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Hogar_A_Recuperados']\n",
    "    print(\"Hogar_A_Recuperados\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Hogar_A_Recuperados. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Hogar_A_Recuperados. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar_A_Remitidos_ingreso_institucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\t\tHogar_A_Fallecidos\tHogar_A_Total\tHogar_PI_Total\tHogar_PI_<19años\tPoliclinico_I_Total\tPoliclinico_I_<19años\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Hogar_A_Remitidos_ingreso_institucional']\n",
    "    print(\"Hogar_A_Remitidos_ingreso_institucional\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Hogar_A_Remitidos_ingreso_institucional. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Hogar_A_Remitidos_ingreso_institucional. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar_A_Fallecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##Hogar_A_Total\tHogar_PI_Total\tHogar_PI_<19años\tPoliclinico_I_Total\tPoliclinico_I_<19años\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    try:\n",
    "        series = province_data[\"Hogar_A_Fallecidos\"]\n",
    "    except:\n",
    "        continue\n",
    "    print(\"Hogar_A_Fallecidos\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in models.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Hogar_A_Fallecidos. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Hogar_A_Fallecidos. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar_A_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\tHogar_PI_Total\tHogar_PI_<19años\tPoliclinico_I_Total\tPoliclinico_I_<19años\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Hogar_A_Total']\n",
    "    print(\"Hogar_A_Total\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Hogar_A_Total. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Hogar_A_Total. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar_PI_Total\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\tHogar_PI_<19años\tPoliclinico_I_Total\tPoliclinico_I_<19años\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Hogar_PI_Total']\n",
    "    print(\"Hogar_PI_Total\t\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Hogar_PI_Total\t. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Hogar_PI_Total\t. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar_PI_<19aÃ±os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\t\tPoliclinico_I_Total\tPoliclinico_I_<19años\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Hogar_PI_<19años']\n",
    "    print(\"Hogar_PI_<19años\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Hogar_PI_<19años. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Hogar_PI_<19años. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policlinico_I_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\tPoliclinico_I_<19años\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Policlinico_I_Total']\n",
    "    print(\"Policlinico_I_Total\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Policlinico_I_Total. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Policlinico_I_Total. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policlinico_I_<19aÃ±os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\t\tPoliclinico_A_Recuperados\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Policlinico_I_<19años']\n",
    "    print(\"Policlinico_I_<19años\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Policlinico_I_<19años. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Policlinico_I_<19años. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policlinico_A_Recuperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\tPoliclinico_A_Remitidos_ingreso_hospitalario\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Policlinico_A_Recuperados']\n",
    "    print(\"Policlinico_A_Recuperados\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Policlinico_A_Recuperados. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Policlinico_A_Recuperados. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policlinico_A_Remitidos_ingreso_hospitalario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\t\tPoliclinico_A_Fallecidos\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Policlinico_A_Remitidos_ingreso_hospitalario']\n",
    "    print(\"Policlinico_A_Remitidos_ingreso_hospitalario\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Policlinico_A_Remitidos_ingreso_hospitalario. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Policlinico_A_Remitidos_ingreso_hospitalario. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policlinico_A_Fallecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\tPoliclinico_A_Total\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Policlinico_A_Fallecidos']\n",
    "    print(\"Policlinico_A_Fallecidos\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Policlinico_A_Fallecidos. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Policlinico_A_Fallecidos. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policlinico_A_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    " ##\tPoliclinico_PI_Total\tPoliclinico_PI_<19años\tTotalAPS_I_Total\tTotalAPS_I_<19años\tTotalAPS_A_Recuperados\tTotalAPS_A_Remitidos\tTotalAPS_A_Fallecidos\tTotalAPS_A_Total\tTotalAPS_PI_Total\tTotalAPS_PI_<19años\tPIDA_hogar\tPIDA_hogar_<19años\tPIDA_hospitalizaciÃ³n\tPIDA_hospitalizaciÃ³n_<19años\tValidaciÃ³n_PIactual\tADAH_Ingresos\tADAH_AltasRecuperados\tADAH_Fallecidos\tDH_Ingresos\tDH_AltasRecuperados\tDH_Fallecidos\tAAH_Ingresos\tAAH_AltasRecuperados\tAAH_Fallecidos\tADAP_Ingresos\tADAP_AltasRecuperados\tADAP_Fallecidos\tDP_Ingresos\tDP_AltasRecuperados\tDP_Fallecidos\tAAP_Ingresos\tAAP_AltasRecuperados\tAAP_Fallecidos\tAATotalAPS_Ingresos\tAATotalAPS_AltasRecuperados\tAATotalAPS_Fallecidos\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "models = {}\n",
    "test_sets = {}\n",
    "d_from_diff = {}\n",
    "train_sets = {}\n",
    "\n",
    "# Iterate over each province\n",
    "for province in province_data_dict.keys():\n",
    "    # Filter data for the current province\n",
    "    province_data = province_data_dict[province]\n",
    "    \n",
    "    # Extract the series to be predicted\n",
    "    series = province_data['Policlinico_A_Total']\n",
    "    print(\"Policlinico_A_Total\")\n",
    "    print(province)\n",
    "    print()\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    test_sets[province] = test\n",
    "    train_sets[province] = train\n",
    "\n",
    "    # Use auto_arima to find the best parameters on the training set\n",
    "    model = pm.auto_arima(train, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "    models[province] = model\n",
    "    \n",
    "    if train.nunique() == 1: \n",
    "        print(f\"The series for province '{province}' is constant.\\n\") \n",
    "        d_from_diff[province] = 0\n",
    "        continue\n",
    "    \n",
    "    # Check for stationarity and apply differencing if needed\n",
    "    d = 0\n",
    "    result = adfuller(train)\n",
    "    while result[1] > 0.05:\n",
    "        train = train.diff().dropna()\n",
    "        d += 1\n",
    "        result = adfuller(train)\n",
    "    d_from_diff[province] = d\n",
    "    print(f\"Best parameters for province '{province}': (d={d} from differencing, d={model.order[1]} d from AutoArima)\\n\")\n",
    "    # Create subplots for ACF and PACF\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plot_acf(train, ax=axes[0])\n",
    "    plot_pacf(train, ax=axes[1])\n",
    "    axes[0].set_title(f'ACF for {province} (MA={model.order[2]})')\n",
    "    axes[1].set_title(f'PACF for {province} (AR={model.order[0]})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "for province in province_data_dict.keys():\n",
    "    auto_model = models[province]\n",
    "    test = test_sets[province]\n",
    "    \n",
    "    auto_predictions = auto_model.predict(n_periods=len(test))\n",
    "    d = d_from_diff[province]\n",
    "    # Fit ARIMA model on the training set\n",
    "    model = ARIMA(train_sets[province], order = (auto_model.order[0], d, auto_model.order[2]))\n",
    "    model_fit = model.fit()\n",
    "    # Make predictions on the test set\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    print(f' AutoArima Predictions for {province}: Policlinico_A_Total. d = {auto_model.order[1]}') \n",
    "    print(auto_predictions)\n",
    "    print()\n",
    "    print(f'Arima Predictions for {province}: Policlinico_A_Total. d = {d}') \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    auto_mae = mean_absolute_error(test, auto_predictions)\n",
    "    auto_mse = mean_squared_error(test, auto_predictions)\n",
    "    auto_rmse = np.sqrt(auto_mse)\n",
    "    auto_mape = np.mean(np.abs((test - auto_predictions) / test)) * 100\n",
    "    auto_nmse = auto_mse / np.var(test)\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(test, predictions)\n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((test - predictions) / test)) * 100\n",
    "    nmse = mse / np.var(test)\n",
    "\n",
    "    print(f'MAE for autoArima: {auto_mae}')\n",
    "    print(f'MSE for autoArima: {auto_mse}')\n",
    "    print(f'RMSE for autoArima: {auto_rmse}')\n",
    "    print(f'MAPE for autoArima: {auto_mape}%')\n",
    "    print(f'NMSEfor autoArima: {auto_nmse}')\n",
    "\n",
    "    print()\n",
    "    print(f'MAE for ARIMA: {mae}')\n",
    "    print(f'MSE for ARIMA: {mse}')\n",
    "    print(f'RMSE for ARIMA: {rmse}')\n",
    "    print(f'MAPE for ARIMA: {mape}%')\n",
    "    print(f'NMSE for ARIMA: {nmse}')\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, auto_predictions, 'x', label='AutoArima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test.index, test, 'o', label='Actual') # Use 'o' for markers \n",
    "    plt.plot(test.index, predictions, 'x', label='Arima Predicted', color='red') # Use 'x' for markers \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(model_fit.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policlinico_PI_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arima_utils import auto_arima_train, evaluate_models\n",
    "\n",
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"Policlinico_PI_Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"Policlinico_PI_Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policlinico_PI_<19aÃ±os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"Policlinico_PI_<19años\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"Policlinico_PI_<19años\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\tTotalAPS_I_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"TotalAPS_I_Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"TotalAPS_I_Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TotalAPS_I_<19aÃ±os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"TotalAPS_I_<19años\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"TotalAPS_I_<19años\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TotalAPS_A_Recuperados\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"TotalAPS_A_Recuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"TotalAPS_A_Recuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TotalAPS_A_Remitidos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"TotalAPS_A_Remitidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"TotalAPS_A_Remitidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TotalAPS_A_Fallecidos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"TotalAPS_A_Fallecidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"TotalAPS_A_Fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TotalAPS_A_Total\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"TotalAPS_A_Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"TotalAPS_A_Total\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TotalAPS_PI_Total\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"TotalAPS_PI_Total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"TotalAPS_PI_Total\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TotalAPS_PI_<19años\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"TotalAPS_PI_<19años\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"TotalAPS_PI_<19años\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIDA_hogar\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"PIDA_hogar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"PIDA_hogar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIDA_hogar_<19aÃ±os\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"PIDA_hogar_<19años\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"PIDA_hogar_<19años\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIDA_hospitalizaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"PIDA_hospitalizaciÃ³n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"PIDA_hospitalizaciÃ³n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIDA_hospitalizaciÃ³n_<19aÃ±os\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"PIDA_hospitalizaciÃ³n_<19años\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"PIDA_hospitalizaciÃ³n_<19años\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ValidaciÃ³n_PIactual\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"ValidaciÃ³n_PIactual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"ValidaciÃ³n_PIactual\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAH_Ingresos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"ADAH_Ingresos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"ADAH_Ingresos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAH_Ingresos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"ADAH_Ingresos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"ADAH_Ingresos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAH_AltasRecuperados\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"ADAH_AltasRecuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"ADAH_AltasRecuperados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAH_Fallecidos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"ADAH_Fallecidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"ADAH_Fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DH_Ingresos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"DH_Ingresos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"DH_Ingresos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DH_AltasRecuperados\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"DH_AltasRecuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"DH_AltasRecuperados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DH_Fallecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"DH_Fallecidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"DH_Fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAH_Ingresos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AAH_Ingresos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AAH_Ingresos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAH_AltasRecuperados\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AAH_AltasRecuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AAH_AltasRecuperados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAH_Fallecidos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AAH_Fallecidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AAH_Fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAP_Ingresos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"ADAP_Ingresos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"ADAP_Ingresos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAP_AltasRecuperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"ADAP_AltasRecuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"ADAP_AltasRecuperados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAP_Fallecidos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"ADAP_Fallecidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"ADAP_Fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP_Ingresos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"DP_Ingresos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"DP_Ingresos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP_AltasRecuperados\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"DP_AltasRecuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"DP_AltasRecuperados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP_Fallecidos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"DP_Fallecidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"DP_Fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAP_Ingresos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AAP_Ingresos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AAP_Ingresos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAP_AltasRecuperados\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AAP_AltasRecuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AAP_AltasRecuperados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAP_Fallecidos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AAP_Fallecidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AAP_Fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AATotalAPS_Ingresos\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AATotalAPS_Ingresos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AATotalAPS_Ingresos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AATotalAPS_AltasRecuperados\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AATotalAPS_AltasRecuperados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AATotalAPS_AltasRecuperados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AATotalAPS_Fallecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, models, test_sets, d_from_diff, train_sets = auto_arima_train(province_data_dict, \"AATotalAPS_Fallecidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(models, test_sets, d_from_diff, train_sets, \"AATotalAPS_Fallecidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
